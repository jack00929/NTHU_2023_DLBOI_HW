{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5692228f-6370-4352-8ba1-016e825e6c93",
      "metadata": {
        "tags": [],
        "id": "5692228f-6370-4352-8ba1-016e825e6c93"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "# National Tsing Hua University\n",
        "\n",
        "### Fall 2023\n",
        "\n",
        "#### 11210IPT 553000\n",
        "\n",
        "#### Deep Learning in Biomedical Optical Imaging\n",
        "\n",
        "## Homework 1\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91844260-2250-4fe6-9b80-6def0405efe8",
      "metadata": {
        "id": "91844260-2250-4fe6-9b80-6def0405efe8"
      },
      "source": [
        "---\n",
        "## Instructions for Completing the Homework:\n",
        "\n",
        "1. **Environment Setup**:\n",
        "   - You have the flexibility to choose your working environment. You can either use [Google Colab](https://colab.research.google.com/) or set up your own local Jupyter Notebook environment.\n",
        "   - If you're new to Google Colab, it allows you to run Jupyter Notebook in the cloud, eliminating setup time and providing free access to GPUs\n",
        "\n",
        "2. **Completing the Homework**:\n",
        "   - Go through the questions provided in the `.ipynb` file and write the necessary code in the designated areas.\n",
        "   - Make sure to test your solutions thoroughly to ensure they work as expected.\n",
        "\n",
        "3. **Submission**:\n",
        "   - After you've completed the homework, commit the `.ipynb` file to your GitHub repository.\n",
        "   - Ensure that your repository is publicly accessible so that it can be evaluated.\n",
        "\n",
        "4. **Learning More**:\n",
        "   - If you need further information or clarification about any `numpy` function, consult [the official numpy documentation](https://docs.scipy.org/doc/numpy/reference/).\n",
        "   - As a quick hack within this notebook: Create a new cell, type in the function name followed by a `?` (e.g., `np.exp?`), and execute the cell. This will pull up the documentation for the function, giving you a brief overview of its usage and parameters.\n",
        "\n",
        "Remember, practice is the key to mastering any skill. Make the best use of resources provided and always strive to explore beyond. Good luck! üçÄüåüüò∫"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "437a4391-d55e-4a81-a1b3-e8c4c47e57e8",
      "metadata": {
        "id": "437a4391-d55e-4a81-a1b3-e8c4c47e57e8"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53421d2b-088d-47d2-9e76-ee2321f27ae9",
      "metadata": {
        "id": "53421d2b-088d-47d2-9e76-ee2321f27ae9"
      },
      "source": [
        "---\n",
        "### ‚úèÔ∏è Question #1 (20pts, each function for 10 pts)\n",
        "\n",
        "In the landmark paper, _[\"ImageNet Classification with Deep Convolutional Neural Networks\"](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)_, by Alex Krizhevsky et al. explored the utilization of various activation functions. A relevant excerpt from the paper is provided below for reference.\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"https://i.imgur.com/73WP75j.png\"  width=\"600\"  alt=\"Segment from the paper\" />\n",
        "</div>\n",
        "\n",
        "**Your task**:\n",
        "1. Carefully analyze the two activation functions highlighted by the red underline in the segment.\n",
        "2. Utilize `numpy` to code and represent the functions corresponding to these activation functions as described in the paper.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "be9f5a8a-3bdb-4c3c-9a59-8a6ae043c208",
      "metadata": {
        "id": "be9f5a8a-3bdb-4c3c-9a59-8a6ae043c208"
      },
      "outputs": [],
      "source": [
        "def func_1(x):\n",
        "    \"\"\"\n",
        "    Compute the output of the first function\n",
        "\n",
        "    Arguments:\n",
        "    x -- A scalar or numpy array of any size.\n",
        "\n",
        "    Return:\n",
        "    s -- func_1(x)\n",
        "    \"\"\"\n",
        "\n",
        "    # YOUR CODE STARTS HERE\n",
        "    s = 1/(1+np.exp(-x))\n",
        "    # YOUR CODE ENDS HERE\n",
        "\n",
        "    return s\n",
        "\n",
        "def func_2(x):\n",
        "    \"\"\"\n",
        "    Compute the output of the second function\n",
        "\n",
        "    Arguments:\n",
        "    x -- A scalar or numpy array of any size.\n",
        "\n",
        "    Return:\n",
        "    s -- func_2(x)\n",
        "    \"\"\"\n",
        "\n",
        "    # YOUR CODE STARTS HERE\n",
        "    s = np.maximum(x,0)\n",
        "    # YOUR CODE ENDS HERE\n",
        "\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "26b65c1b-ae18-41fd-81d4-2cfc6846919e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26b65c1b-ae18-41fd-81d4-2cfc6846919e",
        "outputId": "288bce01-0bec-460b-f150-16816a99db63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "func_1: [0.26894142 0.88079708 0.5       ]\n",
            "func_2: [0 2 0]\n"
          ]
        }
      ],
      "source": [
        "# This is a test block for verification purposes.\n",
        "# You don't need to modify anything in this cell.\n",
        "\n",
        "print(f'func_1: {func_1(np.array([-1, 2, 0]))}')\n",
        "print(f'func_2: {func_2(np.array([-1, 2, 0]))}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1836629-1c86-4922-b335-359bd4b4ef5d",
      "metadata": {
        "id": "d1836629-1c86-4922-b335-359bd4b4ef5d"
      },
      "source": [
        "---\n",
        "### ‚úèÔ∏è Question #2 (10pts)\n",
        "\n",
        "The softmax function is commonly used in classification problems, especially for multiclass classification. It squashes a vector of any size into a vector of values between 0 and 1 that sum up to 1. This property makes it useful for interpreting the output values as probabilities.\n",
        "\n",
        "Given an input **vector** $ z = [z_1, z_2, \\dots, z_n] $, the softmax function is defined as:\n",
        "\n",
        "$$ \\sigma(z)_i = \\frac{e^{z_i}}{\\sum_{j=1}^{n} e^{z_j}} $$\n",
        "\n",
        "For each $ i $ from 1 to $ n $.\n",
        "\n",
        "In essence, the softmax function computes the exponential (pointwise) of each element of the input vector and then normalizes it by dividing by the sum of these exponentials. This process ensures that:\n",
        "\n",
        "1. Each element of the output vector lies between 0 and 1.\n",
        "2. The sum of the elements of the output vector is 1.\n",
        "\n",
        "**Your Task**:\n",
        "1. Implement the softmax function using `numpy`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2b58281-21b7-47de-85a8-e057faffd288",
      "metadata": {
        "id": "c2b58281-21b7-47de-85a8-e057faffd288"
      },
      "outputs": [],
      "source": [
        "def softmax(z):\n",
        "    \"\"\"\n",
        "    Compute the softmax of vector z.\n",
        "\n",
        "    Arguments:\n",
        "    z -- A 1D numpy array.\n",
        "\n",
        "    Return:\n",
        "    s -- softmax(z)\n",
        "    \"\"\"\n",
        "\n",
        "    # YOUR CODE STARTS HERE\n",
        "    z_exp = np.exp(z)\n",
        "    z_sum = sum(np.exp(z))\n",
        "    s = z_exp/z_sum\n",
        "    # YOUR CODE ENDS HERE\n",
        "\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ae80f98-9041-4bfd-ace7-03426f15a16e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ae80f98-9041-4bfd-ace7-03426f15a16e",
        "outputId": "6c6a5df6-88aa-45b3-94fd-0628989508f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax Output: [0.04201007 0.84379473 0.1141952 ]\n"
          ]
        }
      ],
      "source": [
        "# This is a test block for verification purposes.\n",
        "# You don't need to modify anything in this cell.\n",
        "\n",
        "print(f'Softmax Output: {softmax(np.array([-1, 2, 0]))}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38b98220-b072-485d-9f06-da280963ff2b",
      "metadata": {
        "tags": [],
        "id": "38b98220-b072-485d-9f06-da280963ff2b"
      },
      "source": [
        "---\n",
        "### ‚úèÔ∏è Question #3 (30pts, each part for 10 pts)\n",
        "\n",
        "The objective of this question is to understand and implement three commonly used loss functions in machine learning: L1 and L2 Loss measure differences between predicted and actual values; and the Cross-Entropy Loss compares predicted probabilities to actual class labels.\n",
        "\n",
        "<br/>\n",
        "\n",
        "#### **Part A: L1 Loss Implementation**\n",
        "\n",
        "**L1 loss**, often referred to as the absolute error, calculates the absolute differences between the true values and the predictions. It's given by:\n",
        "\n",
        "$$ \\text{L1}(\\hat{y}, y) = \\sum_{i} |y^{(i)} - \\hat{y}^{(i)}| $$\n",
        "\n",
        "where:\n",
        "\n",
        "- $ y $ represents the true values.\n",
        "- $ \\hat{y} $ represents the predicted values.\n",
        "\n",
        "**Your task**:\n",
        "1. Implement the L1 loss using a numpy vectorized approach. The function `np.abs(x)` may be useful for computing the absolute value of `x`.\n",
        "\n",
        "<br/>\n",
        "\n",
        "#### **Part B: L2 Loss Implementation**\n",
        "\n",
        "**L2 loss**, also known as the squared error, computes the squared differences between the true values and the predictions. It's mathematically expressed as:\n",
        "\n",
        "$$ \\text{L2}(\\hat{y},y) = \\sum_{i} (y^{(i)} - \\hat{y}^{(i)})^2 $$\n",
        "\n",
        "where:\n",
        "\n",
        "- $ y $ represents the true values.\n",
        "- $ \\hat{y} $ represents the predicted values.\n",
        "\n",
        "**Your task**:\n",
        "1. Implement the L2 loss in a numpy vectorized manner.\n",
        "\n",
        "<br/>\n",
        "\n",
        "#### **Part C: Ceoss-Entropy Loss Implementation**\n",
        "**Cross-Entropy loss** is commonly used in classification problems. It is defined as:\n",
        "\n",
        "<br/>\n",
        "\n",
        "$$ \\text{CE}(y, \\hat{y}) = -\\sum_{i} y^{(i)} \\log(\\hat{y}^{(i)} + \\epsilon)\\ $$\n",
        "where:\n",
        "\n",
        "- $ y $ is the true distribution (the ground truth labels) in a shape (1, num_class), and $i$ specifies the index of the class.\n",
        "- $ \\hat{y} $ is the predicted distribution (the predictions from your model), also in a shape (1, num_class)\n",
        "- The sum is taken over all the classes.\n",
        "- Note the $\\epsilon$ is applied to prevent the $\\log()$ outputs negative infinity.\n",
        "\n",
        "**Your task**:\n",
        "1. Implement the CE loss in a numpy vectorized manner.\n",
        "<br/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "10b1c563-3f58-4fa3-a2ce-42603b72d3eb",
      "metadata": {
        "id": "10b1c563-3f58-4fa3-a2ce-42603b72d3eb"
      },
      "outputs": [],
      "source": [
        "def L1(yhat, y):\n",
        "    \"\"\"\n",
        "    Compute the L1 loss.\n",
        "\n",
        "    Arguments:\n",
        "    yhat -- vector of size m (predicted labels)\n",
        "    y -- vector of size m (true labels)\n",
        "\n",
        "    Returns:\n",
        "    loss -- the value of the L1 loss function defined above\n",
        "    \"\"\"\n",
        "\n",
        "    # YOUR CODE STARTS HERE\n",
        "    loss = sum(abs(y-yhat))\n",
        "    # YOUR CODE ENDS HERE\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def L2(yhat, y):\n",
        "    \"\"\"\n",
        "    Compute the L2 loss.\n",
        "\n",
        "    Arguments:\n",
        "    yhat -- vector of size m (predicted labels)\n",
        "    y -- vector of size m (true labels)\n",
        "\n",
        "    Returns:\n",
        "    loss -- the value of the L2 loss function defined above\n",
        "    \"\"\"\n",
        "\n",
        "    # YOUR CODE STARTS HERE\n",
        "    loss = sum((y-yhat)**2)\n",
        "    # YOUR CODE ENDS HERE\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def CE(yhat, y, epsilon=1e-6):\n",
        "    \"\"\"\n",
        "    Compute the cross entropy loss\n",
        "\n",
        "    Arguments:\n",
        "    yhat -- vector of size m (predicted distributon)\n",
        "    y -- vector of size m (true labels)\n",
        "\n",
        "    Returns:\n",
        "    loss -- the value of the cross entropy loss function defined above\n",
        "    \"\"\"\n",
        "    # YOUR CODE STARTS HERE\n",
        "    loss = -sum(sum(y*np.log(yhat+epsilon)))\n",
        "    # YOUR CODE ENDS HERE\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "c9d1e4c9-b8e2-400f-aa56-214ca0c70f2c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9d1e4c9-b8e2-400f-aa56-214ca0c70f2c",
        "outputId": "94209648-bee6-4b84-bba6-959ae53f249f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1: 1.1\n",
            "L2: 0.43\n",
            "CE: 0.3285017058623233\n"
          ]
        }
      ],
      "source": [
        "# This is a test block for verification purposes.\n",
        "# You don't need to modify anything in this cell.\n",
        "\n",
        "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
        "y = np.array([1, 0, 0, 1, 1])\n",
        "\n",
        "print(f'L1: {L1(yhat, y)}')\n",
        "print(f'L2: {L2(yhat, y)}')\n",
        "\n",
        "phat = np.array([[0.9, 0.05, 0.05], [0.1, 0.8, 0.1]])\n",
        "y = np.array([[1, 0, 0], [0, 1, 0]])\n",
        "print(f'CE: {CE(phat, y)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9815711e-65bc-4a0b-a850-af2fc6b8c8a3",
      "metadata": {
        "id": "9815711e-65bc-4a0b-a850-af2fc6b8c8a3"
      },
      "source": [
        "---\n",
        "### ‚úèÔ∏è Question #4 (20pts, each step for 5 pts)\n",
        "\n",
        "   Batch normalization, introduced in the paper _[\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\"](https://arxiv.org/abs/1502.03167)_ by S. Ioffe et al., serves as a cornerstone technique in deep learning. It standardizes the inputs of each layer, thus enhancing the efficiency of network learning. The primary motive behind its inception was to counter the internal covariate shift dilemma. By normalizing activations across the network, batch normalization not only enhances training speed but also bolsters model performance.\n",
        "\n",
        "In this exercise, you are tasked to implement **Algorithm 1** presented in the paper shown below. **Note that this algorithm is applied differently during training and inference.** For further details, please refer to Algorithm 2 in the paper.\n",
        "\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"https://i.imgur.com/vHCVvBj.png\"  width=\"400\"  alt=\"centered image\" />\n",
        "</div>\n",
        "\n",
        "\n",
        "Below are the steps for **Algorithm 1**:\n",
        "\n",
        "**Input:**\n",
        "- Mini-batch of input values: $B = \\{x_1, x_2, ..., x_m\\}$\n",
        "- Parameters to learn: $\\gamma$, $\\beta$\n",
        "\n",
        "**Output:**\n",
        "- Batch-normalized values: $y_i = BN_{\\gamma,\\beta}(x_i)$\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "1. **Compute the mini-batch mean:**  \n",
        "   $$\n",
        "   \\mu_B = \\frac{1}{m} \\sum_{i=1}^{m} x_i\n",
        "   $$\n",
        "\n",
        "2. **Compute the mini-batch variance:**  \n",
        "   $$\n",
        "   \\sigma^2_B = \\frac{1}{m} \\sum_{i=1}^{m} (x_i - \\mu_B)^2\n",
        "   $$\n",
        "\n",
        "3. **Normalize the values:**  \n",
        "   Use the mean and variance to normalize the values in the mini-batch. Add a small constant, $ \\epsilon $, for numerical stability.\n",
        "   $$\n",
        "   \\hat{x}_{i} = \\frac{x_i - \\mu_B}{\\sqrt{\\sigma^2_B + \\epsilon}}\n",
        "   $$\n",
        "\n",
        "4. **Scale and Shift:**  \n",
        "   Use the parameters $ \\gamma $ and $ \\beta $ to scale and shift the normalized values.\n",
        "   $$\n",
        "   y_i = \\gamma \\hat{x}_{i} + \\beta \\equiv BN_{\\gamma,\\beta}(x_i)\n",
        "   $$\n",
        "\n",
        "**Notes:**\n",
        "\n",
        "1. Do not use any deep learning frameworks or in-built batch normalization functions.\n",
        "2. Make sure to incorporate the small constant $ \\epsilon $ during normalization to avoid division by zero.\n",
        "\n",
        "**Your Task:**\n",
        "\n",
        "1. Following the steps provided above, write the code to implement the Batch Normalization algorithm. Make sure to consider the notes and constraints while working on your solution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "90a6d404-443a-49e8-8b98-2fb517b626a7",
      "metadata": {
        "id": "90a6d404-443a-49e8-8b98-2fb517b626a7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def batch_normalization(X, gamma, beta, epsilon=1e-6):\n",
        "    \"\"\"\n",
        "    Apply Batch Normalization as per the given algorithm.\n",
        "\n",
        "    Arguments:\n",
        "    B       -- numpy array of any shape, the input mini-batch\n",
        "    gamma   -- numpy array of shape matching B's, scale parameter\n",
        "    beta    -- numpy array of shape matching B's, shift parameter\n",
        "    epsilon -- small constant for numerical stability (default is 1e-6)\n",
        "\n",
        "    Returns:\n",
        "    y_i     -- batch-normalized values\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 1: Compute the mini-batch mean\n",
        "    mu_B = sum(B)/5\n",
        "\n",
        "    # Step 2: Compute the mini-batch variance\n",
        "    sigma_B = sum((B- mu_B)**2)/5\n",
        "\n",
        "    # Step 3: Normalize\n",
        "    x_hat = (B- mu_B)/np.sqrt(sigma_B+epsilon)\n",
        "\n",
        "    # Step 4: Scale and shift\n",
        "    y_i = gamma*x_hat+beta\n",
        "\n",
        "    return y_i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "68fa91b5-6999-4ab8-a31e-6714f0384462",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68fa91b5-6999-4ab8-a31e-6714f0384462",
        "outputId": "6f73ecab-cdd5-4e92-d4c0-69472afa2e4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.41421356 -0.70710678  0.          0.70710678  1.41421356]\n"
          ]
        }
      ],
      "source": [
        "# This is a test block for verification purposes.\n",
        "# You don't need to modify anything in this cell.\n",
        "\n",
        "B = np.array([10, 20, 30, 40, 50])\n",
        "gamma = 1.0\n",
        "beta = 0.0\n",
        "\n",
        "print(batch_normalization(B, gamma, beta))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba22d8e8-4dcf-432e-9c56-28667a45c449",
      "metadata": {
        "id": "ba22d8e8-4dcf-432e-9c56-28667a45c449"
      },
      "source": [
        "---\n",
        "### ‚úèÔ∏è Question #5 (20pts, each step for 5 pts)\n",
        "\n",
        "In image processing tasks, often you'll find yourself needing to convert between different color spaces. OpenCV reads images in BGR (Blue, Green, Red) format by default. However, many image processing libraries (including matplotlib, which you might use for displaying images) expect the channels to be in RGB (Red, Green, Blue) format. Thus, converting between these formats is a common task.\n",
        "\n",
        "**Notes**:\n",
        "- You need to upload **'hw1_img.jpg'** into your environment.\n",
        "- Ensure you handle the image channels correctly during conversion.\n",
        "- Replace all **...** in the code with your implementations.\n",
        "\n",
        "**Your task**:\n",
        "1. Read the image **'hw1_img.jpg'**. Ensure your image path is correct.\n",
        "2. Convert the image from BGR to RGB. You should NOT use any in-built OpenCV functions for this conversion. Instead, use numpy operations to rearrange the channels.\n",
        "3. Print the shape of the image, displaying the height, width, and the number of channels (depth).\n",
        "4. Crop the region you are interested in (region of interested, ROI), then show it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "17f3f9b9-6f8c-4e8e-9cd8-38434d7a503a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "17f3f9b9-6f8c-4e8e-9cd8-38434d7a503a",
        "outputId": "dd26f03d-c757-43fb-b9e0-384c0756f678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image file path is: Ellipsis\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ad53301829e5>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Read the image using cv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Display the BGR image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Can't convert object to 'str' for 'filename'"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Specify the path to your image file\n",
        "image_path = ...\n",
        "\n",
        "print(f'Image file path is: {image_path}')\n",
        "\n",
        "# Read the image using cv2\n",
        "img = cv2.imread(image_path)\n",
        "\n",
        "# Display the BGR image\n",
        "plt.imshow(img)\n",
        "plt.title('BGR image')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Step 2: Convert the BGR image to RGB using numpy\n",
        "image_rgb = img[...]\n",
        "\n",
        "# Display the RGB image\n",
        "plt.imshow(image_rgb)\n",
        "plt.title('RGB image')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Step 3: Print the shape of the RGB image\n",
        "print(f'The shape of this image is: {...}')\n",
        "\n",
        "# Step 4 Display the cropped image.\n",
        "plt.imshow(image_rgb[...])\n",
        "plt.title('Cropped image')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qy54mzdMR7ae"
      },
      "id": "Qy54mzdMR7ae",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}